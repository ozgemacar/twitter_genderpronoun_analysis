# -*- coding: utf-8 -*-
"""gender_dataanalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17iip3X2__UiwLJjVMwKn_0WYRQRJq_rM
"""

import glob
import gzip
import json
import re
from collections import Counter

from google.colab import drive
drive.mount('/content/gdrive')

def check_pronoun(text):
    regex = r"(\sshe\sher\shers\s)|(\sshe\sher\s)|(\she\shim\shis\s)|(\she\shim\s)|(\sthey\sthem\s)|(\sthey\sthem\stheirs\s)|(\sze\szir\szirs\s)|(\sze\szir\szis\s)|(\sze\szir\s)|(\sxe\sxem\sxir\s)|(\sxe\sxem\sxirs\s)|(\sxe\sxem\s)|(\ssie\shir\shirs\s)|(\ssie\shir\s)"
    match = re.search(regex, text, re.MULTILINE | re.IGNORECASE)
    if match == None:
        return False
    else:
        return True

pronoun_status = {}

#regex updated version

all_files = glob.glob("/content/gdrive/MyDrive/Research/GenderPronoun/Data/All in one/*.jsons.gz")

with open("alldata_withpronoun_2011-2020.json", "w") as outfile:
  for file in all_files:
      with gzip.open(file, 'rt') as fl:
          for line in fl:
              temp = json.loads(line)
              str_desc = temp["user"]["description"]
              dash_removed = str_desc.replace("/", " ")
              comma_removed = dash_removed.replace(",", " ")
              dot_removed = comma_removed.replace(".", " ")
              end_whitespace = dot_removed + ""
              result=check_pronoun(end_whitespace)
              if result == True:
                pronoun_status["id_str"] = temp["user"]["id_str"]
                pronoun_status["account_created_timestamp"] = temp["user"]["timestamp"]
                pronoun_status["current_tweet_timestamp"] = temp["timestamp"]
                pronoun_status["description"] = end_whitespace
                json.dump(pronoun_status, outfile)
                outfile.write('\n')

#to obtain data file with tweet information

all_files = glob.glob("/content/gdrive/MyDrive/Research/GenderPronoun/Data/All in one/*.jsons.gz")

with open("tweetincluded_alldata_withpronoun_2011-2020.json", "w") as outfile:
  for file in all_files:
      with gzip.open(file, 'rt') as fl:
          for line in fl:
              temp = json.loads(line)
              str_desc = temp["user"]["description"]
              dash_removed = str_desc.replace("/", " ")
              comma_removed = dash_removed.replace(",", " ")
              dot_removed = comma_removed.replace(".", " ")
              end_whitespace = dot_removed + ""
              result=check_pronoun(end_whitespace)
              if result == True:
                pronoun_status["id_str"] = temp["user"]["id_str"]
                pronoun_status["account_created_timestamp"] = temp["user"]["timestamp"]
                pronoun_status["current_tweet_timestamp"] = temp["timestamp"]
                pronoun_status["description"] = end_whitespace
                pronoun_status["tweet"] = temp["text"]
                pronoun_status["friends_count"] = temp["user"]["friends_count"]
                pronoun_status["followers_count"] = temp["user"]["followers_count"]
                json.dump(pronoun_status, outfile)
                outfile.write('\n')