# -*- coding: utf-8 -*-
"""gender_dataanalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17iip3X2__UiwLJjVMwKn_0WYRQRJq_rM
"""

import glob  #If you want to go through more than one file.
import gzip  #If you will use zip files. 
import json
import re
from collections import Counter

DATAFILE = "ENTER YOUR FILEPATH HERE"  #It includes the user objects from Twitter line by line.
NEWFILENAME = "THE FILE NAME FOR YOUR OUTFILE.json"

def check_pronoun(text):
    regex = r"(\sshe\sher\shers\s)|(\sshe\sher\s)|(\she\shim\shis\s)|(\she\shim\s)|(\sthey\sthem\s)|(\sthey\sthem\stheirs\s)|(\sze\szir\szirs\s)|(\sze\szir\szis\s)|(\sze\szir\s)|(\sxe\sxem\sxir\s)|(\sxe\sxem\sxirs\s)|(\sxe\sxem\s)|(\ssie\shir\shirs\s)|(\ssie\shir\s)"
    match = re.search(regex, text, re.MULTILINE | re.IGNORECASE)
    if match == None:
        return False
    else:
        return True

pronoun_status = {}

#regex updated version

all_files = glob.glob(DATAFILE/*.jsons.gz") #Use glob library if you have more than one file to go through. Otherwise, simply use open() function.

with open(NEWFILENAME, "w") as outfile:
  for file in all_files:
      with gzip.open(file, 'rt') as fl:
          for line in fl:
              temp = json.loads(line)
              str_desc = temp["user"]["description"]
              dash_removed = str_desc.replace("/", " ")
              comma_removed = dash_removed.replace(",", " ")
              dot_removed = comma_removed.replace(".", " ")
              end_whitespace = dot_removed + ""
              result=check_pronoun(end_whitespace)
              if result == True:
                pronoun_status["id_str"] = temp["user"]["id_str"]
                pronoun_status["account_created_timestamp"] = temp["user"]["timestamp"]
                pronoun_status["current_tweet_timestamp"] = temp["timestamp"]
                pronoun_status["description"] = end_whitespace
                json.dump(pronoun_status, outfile)
                outfile.write('\n')

#You can use either the above code or the below, it will construct differently each line according to your needs.
                      
#to obtain data file with tweet information

all_files = glob.glob(DATAFILE/*.jsons.gz")

with open(NEWFILENAME, "w") as outfile:
  for file in all_files:
      with gzip.open(file, 'rt') as fl:
          for line in fl:
              temp = json.loads(line)
              str_desc = temp["user"]["description"]
              dash_removed = str_desc.replace("/", " ")
              comma_removed = dash_removed.replace(",", " ")
              dot_removed = comma_removed.replace(".", " ")
              end_whitespace = dot_removed + ""
              result=check_pronoun(end_whitespace)
              if result == True:
                pronoun_status["id_str"] = temp["user"]["id_str"]
                pronoun_status["account_created_timestamp"] = temp["user"]["timestamp"]
                pronoun_status["current_tweet_timestamp"] = temp["timestamp"]
                pronoun_status["description"] = end_whitespace
                pronoun_status["tweet"] = temp["text"]
                pronoun_status["friends_count"] = temp["user"]["friends_count"]
                pronoun_status["followers_count"] = temp["user"]["followers_count"]
                json.dump(pronoun_status, outfile)
                outfile.write('\n')
